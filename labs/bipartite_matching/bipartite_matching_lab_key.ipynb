{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "from ortools.linear_solver import pywraplp as OR\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import copy\n",
    "import pickle\n",
    "from bokeh import palettes\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "from bokeh.models import (GraphRenderer, Circle, MultiLine, StaticLayoutProvider,\n",
    "                          HoverTool, TapTool, EdgesAndLinkedNodes, NodesAndLinkedEdges,\n",
    "                          ColumnDataSource, LabelSet, NodesOnly)\n",
    "from matching import *\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Routing Bipartite Matching Lab\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* Construct the taxi-routing problem as a bipartite graph.\n",
    "* Use the maximum cardinality matching problem to solve the taxi-routing problem.\n",
    "* Compare the original and optimal solutions to the taxi-routing problem.\n",
    "    \n",
    "<font color='red'> **Instructor Comments** </font>\n",
    "\n",
    "<font color='blue'> **Solutions** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Bipartite Graph Formulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the taxi trips information as well as NYC street nodes and arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.read_csv('data/2013-09-01_trip_data_manhattan.csv').drop(columns='id')\n",
    "nodes_df = pd.read_csv('data/nyc_nodes_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "arcs_df = pd.read_csv('data/nyc_links_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "with open('data/time_map.pkl', 'rb') as f:\n",
    "    times = pickle.load(f) # A dictionary with dropoff-pickup pairs as keys and travel times as values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at an example input. Each trip consists of ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of example trip_ids\n",
    "ex_trips = [81247, 82007, 81152, 81954, 82250, 81855, 81114, 81090, 82851, 82629]\n",
    "# Locate the corresponding trip information\n",
    "trips = trips_df.iloc[ex_trips]\n",
    "trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Assume that a taxi handles two consecutive trips $i$ and $j$ (in order), where the drop-off time at location $d_i$ is $T^d_i$ and the pickup time at location $p_j$ is $T^p_j$. What is the *elapsed time* between the drop-off time of trip $i$ and the pickup time of trip $j$ (express in terms of $T^d_i$ and $T^p_j$) ?\n",
    "\n",
    "**A:** <font color='blue'> The *elapsed time* is $T^p_j - T^d_i$.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Assume that $time(d_i, p_j)$ is the time needed to travel between location point $d_i$ and location point $p_j$. What relationship must hold between the *elasped time* between the drop-off time of trip $i$ and the pickup time of trip $j$ and $time(d_i, p_j)$ in order for a taxi to cover both trip $i$ and trip $j$ (express in terms of $time(d_i, p_j), T^d_i$ and $T^p_j$)? What does your inequality mean?\n",
    "\n",
    "**A:** <font color='blue'> $time(d_i, p_j) \\leq T^p_j - T^d_i$. It means that a taxi can reach the new pickup at $p_j$ in time after dropping off the fare at $d_i$. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max waiting time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify edges\n",
    "max_waiting_time = 10\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                    edges.append((DO_node, PU_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the maximum cardinality matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.bipartite.maximum_matching(B, DO_nodes)\n",
    "print('size of max cardinality matching:', int(len(match)/2)) # divided by two because the output edges are directed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What is the minimum number of taxis needed to cover all the trips according to the maximum cardinality matching?\n",
    "\n",
    "**A:** <font color='blue'> 4 taxis.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the information given by maximum cardinality matching to track down the optimal taxi trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_paths = match_to_path(match, trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ex_bipartite(B, match, opt_paths, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Interpret one optimal taxi trajectory based on the graph above using the location ids (remember each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")).\n",
    "\n",
    "**A:** <font color='blue'> 586->581->1597 or 590->305->889->752->751 or 2010->1312->46->1796->480 or 2588->1314->1312->158 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the corresponding taxi paths on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = street_network(nodes_df, arcs_df)\n",
    "plot_taxi_route(G, opt_paths, nodes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bipartite Graph Formulation (At Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of selecting a sample selection of taxi trips, try filter the trips by time window of interest. The following example selects all the trips from 5 pm to 5:15 pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trips by time window of interest\n",
    "start_time = 1020\n",
    "end_time = 1035\n",
    "trips = trips_df.copy()\n",
    "trips = trips[(trips.start_time >= start_time) & \n",
    "              (trips.start_time + trips.trip_time <= end_time)].copy()\n",
    "trips.start_time = trips.start_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes and edges are defined similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify nodes - each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")\n",
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify edges\n",
    "max_waiting_time = 10\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                    edges.append((DO_node, PU_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.bipartite.maximum_matching(B, DO_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size of max cardinality matching:', len(match) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of unmatched nodes (minimum number of taxis needed)\n",
    "# TODO: Assign num_taxi with the minimum number of taxis needed\n",
    "# num_taxi = XXX\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_taxi = len(DO_nodes) - len(match)/2\n",
    "### END SOLUTION\n",
    "\n",
    "print('min number of taxis needed: ', num_taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum matching problem can also be formulated via an IP formulation.\n",
    "$$\\begin{align*}\n",
    "\\min \\quad & \\sum_{e \\in E}x_e \\\\\n",
    "\\text{s.t.} \\quad &  \\sum_{e \\in \\delta(v)} x_e \\leq 1 \\quad \\forall v \\in P \\cup D & (1)\\\\\n",
    "\\quad & x_e \\in \\{0,1\\} \\quad \\forall e \\in E & (2)\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "where, $\\delta(v)$ is the set of edges incident on the vertex $v \\in P \\cup D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary that stores the list of edges adjacent to node\n",
    "incident = dict()\n",
    "for v in (DO_nodes + PU_nodes):\n",
    "    incident[v] = [edge for edge in edges if v in edge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = OR.Solver('taxi_bipartite', OR.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "# Decision variables\n",
    "x = {}  \n",
    "for e in edges:\n",
    "    x[e] = solver.IntVar(0, 1, ('(%s)' % str(e)))\n",
    "\n",
    "solver.Maximize(sum(x[e] for e in edges))\n",
    "\n",
    "for v in (DO_nodes + PU_nodes):\n",
    "    if v in incident.keys():\n",
    "        solver.Add(sum(x[e] for e in incident[v]) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.Solve()\n",
    "print('Solution:')\n",
    "print('Objective value =', solver.Objective().Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check our answer by reducing the max matching problem to a max flow problem - the max flow value should be equal to the size of max cardinality matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(PU_nodes + DO_nodes + ['s'] + ['t'])\n",
    "for edge in edges:\n",
    "    G.add_edge(edge[0], edge[1], capacity = 1)\n",
    "for DO_node in DO_nodes:\n",
    "    G.add_edge('s', DO_node, capacity = 1)\n",
    "for PU_node in PU_nodes:\n",
    "    G.add_edge(PU_node, 't', capacity = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_value, flow_dict = nx.maximum_flow(G, \"s\", \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max flow value: ', flow_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another alogrithm to solve max flow\n",
    "from networkx.algorithms.flow import shortest_augmenting_path\n",
    "print('max flow value: ', nx.maximum_flow(G, \"s\", \"t\", flow_func=shortest_augmenting_path)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(start_time, end_time, trips_df, max_waiting_time):\n",
    "    # filter trips by time window of interest\n",
    "    trips = trips_df.copy()\n",
    "    trips = trips[(trips.start_time >= start_time) & \n",
    "                  (trips.start_time + trips.trip_time <= end_time)].copy()\n",
    "    trips.start_time = trips.start_time - start_time\n",
    "\n",
    "    # create a dictionary to map the location pairs to trip time\n",
    "    loc_time = dict()\n",
    "    for index, row in arcs_df.iterrows():\n",
    "        i = row['start']\n",
    "        j = row['end']\n",
    "        delay = row['trip_time']\n",
    "        loc_time[(i, j)] = delay\n",
    "    # Intialize nodes and edges\n",
    "    DO_nodes = list()\n",
    "    PU_nodes = list()\n",
    "    edges = list()\n",
    "    # Initialize a dict that maps a PU node to a DO node\n",
    "    PUtoDO = dict()\n",
    "    # Specify nodes - each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")\n",
    "    for index, row in trips.iterrows():\n",
    "        s = row['start_node']\n",
    "        t = row['end_node']\n",
    "        s_t = row['start_time']\n",
    "        t_t = s_t + row['trip_time']\n",
    "        DO_node = (int(t), t_t, index, 'DO')\n",
    "        PU_node = (int(s), s_t, index, 'PU')\n",
    "        DO_nodes.append(DO_node)\n",
    "        PU_nodes.append(PU_node)\n",
    "        PUtoDO[PU_node] = DO_node\n",
    "    DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "    PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "    \n",
    "    # Specify edges\n",
    "    for DO_node in DO_nodes:\n",
    "        for PU_node in PU_nodes:\n",
    "            if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "                break\n",
    "            else:\n",
    "                if PU_node[1] >= DO_node[1]:\n",
    "                    time = times[(DO_node[0], PU_node[0])]\n",
    "                    if ((PU_node[1] - DO_node[1]) - max_waiting_time <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                        edges.append((DO_node, PU_node))\n",
    "    \n",
    "    # load the model\n",
    "    B = nx.Graph()\n",
    "    # Add nodes with the node attribute \"bipartite\"\n",
    "    B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "    B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "    # Add edges only between nodes of opposite node sets\n",
    "    B.add_edges_from(edges)\n",
    "    \n",
    "    top_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    match = nx.bipartite.maximum_matching(B, top_nodes)\n",
    "    num_taxi = len(DO_nodes) - len(match)/2\n",
    "\n",
    "    return match, num_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match, num_taxi = max_match(1020, 1035, trips_df, 10)\n",
    "print('max cardinality matching:', len(match)/2)\n",
    "print('min number of taxis needed to cover all trips:', num_taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try expanding the time window to 5-6 pm and restrict the max waiting time to 5 mininutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = max_match(1020, 1080, trips_df, 5)\n",
    "print('max cardinality matching:', len(match)/2)\n",
    "print('min number of taxis needed to cover all trips:', num_taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compare one day's taxi routing solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the result of a day's data\n",
    "with open('data/day_match.pkl', 'rb') as f:\n",
    "    match = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal taxi paths\n",
    "opt_paths = match_to_path(match, trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the street network\n",
    "G = street_network(nodes_df, arcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the routes with more than 1 trip\n",
    "opt_paths2 = []\n",
    "for path in opt_paths:\n",
    "    if len(path) > 1:\n",
    "        opt_paths2.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_taxi_route(G, opt_paths2[:5], nodes_df,'Optimal Sample Taxi Routes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the original paths of the taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_paths = get_og_path(trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the routes with more than 1 trip\n",
    "og_paths2 = []\n",
    "for path in og_paths:\n",
    "    if len(path) > 1:\n",
    "        og_paths2.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_taxi_route(G, og_paths2[:5], nodes_df,'Original Sample Taxi Routes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare statistics of the taxi routings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_stats = get_taxi_stats(opt_paths, trips_df)\n",
    "og_stats = get_taxi_stats(og_paths, trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics for the original taxi routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stats(og_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics for the optimal taxi routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stats(opt_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(og_stats, opt_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to compare different taxi routings is to compare their distribution of taxis over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_data = get_day_dist(og_paths, opt_paths, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_taxi_dist(day_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_circulating(day_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
